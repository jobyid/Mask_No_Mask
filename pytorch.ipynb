{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00000-7d6e5219-bb52-45f3-9166-10d6820eb775",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "3898f250",
        "execution_millis": 1070,
        "execution_start": 1616507900059,
        "deepnote_cell_type": "code"
      },
      "source": "import data_loader as dl\nimport cnn_class1 as cnn\nimport torch\nimport numpy as np",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00001-e5b9b8bb-e635-4b81-933c-5c3c70e4a817",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a2bbb8db",
        "execution_millis": 6,
        "execution_start": 1616507901134,
        "deepnote_cell_type": "code"
      },
      "source": "data_loader, data = dl.load_data('./dataset',batch_size=8, train=True)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00001-bfca55a6-ed0e-4c45-8c3b-57639fdd2f3a",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "39b53f45",
        "execution_millis": 15,
        "execution_start": 1616507901149,
        "deepnote_cell_type": "code"
      },
      "source": "\"\"\"total_count = len(model_dataset)\n# Also you shouldn't use transforms here but below\ntrain_count = int(0.7 * total_count)\nvalid_count = int(0.2 * total_count)\ntest_count = total_count - train_count - valid_count\ntrain_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\n    model_dataset, (train_count, valid_count, test_count)\n)\"\"\"",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "\"total_count = len(model_dataset)\\n# Also you shouldn't use transforms here but below\\ntrain_count = int(0.7 * total_count)\\nvalid_count = int(0.2 * total_count)\\ntest_count = total_count - train_count - valid_count\\ntrain_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\\n    model_dataset, (train_count, valid_count, test_count)\\n)\""
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Not sure what to do now?? I think we ahve a train test set of data ready to go. we have the data loaded above. Now we need the model I think and the training loop \n",
      "metadata": {
        "tags": [],
        "cell_id": "00003-c5e330bf-b322-4aee-9de6-efcb7e52ed8c",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00003-b8254acc-5092-4448-b687-eacb4c60e969",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "4d5e9b14",
        "execution_millis": 292,
        "execution_start": 1616507907927,
        "deepnote_cell_type": "code"
      },
      "source": "model = cnn.mask_net()",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00006-f92f7337-330d-4f29-99b5-59444dc629dd",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b4897cf8",
        "execution_millis": 2,
        "execution_start": 1616507910675,
        "deepnote_cell_type": "code"
      },
      "source": "epochs = 10\noptimizer = cnn.optimizer\ncriterion = cnn.criterion",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00009-de0b7474-e591-48a7-9143-bde4ce3b7825",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "5e12c087",
        "execution_millis": 356,
        "execution_start": 1616507912925,
        "deepnote_cell_type": "code"
      },
      "source": "images, labels = next(iter(data_loader))\n# OR THIS ONE\n\nepochs = 10\nsteps = 0\nrunning_loss = 0\nprint_every = 10\nfor epoch in range(epochs):\n    for inputs, labels in data_loader:\n        steps += 1\n        # Move input and label tensors to the default device\n        inputs, labels = data_loader\n        \n        optimizer.zero_grad()\n        \n        output = model.forward(inputs)  # 1) Forward pass\n        loss = criterion(output, labels) # 2) Compute loss\n        loss.backward()                  # 3) Backward pass\n        optimizer.step()                 # 4) Update model\n        \n        running_loss += loss.item()\n        \n           \n        if steps % print_every == 0:\n            test_loss = 0\n            accuracy = 0\n            model.eval()\n            \n            # need to take this out since we are just running the whole data\n            \"\"\"with torch.no_grad():\n                for inputs, labels in testloader:\n                    inputs, labels = valid_dataset\n                    \n                    output = model.forward(inputs)\n                    batch_loss = criterion(output, labels)\n                    test_loss += batch_loss.item()\n                    \n                    #calculate accuracy\n                    ps = torch.exp(output)\n                    top_p, top_class = ps.topk(1, dim=1)\n                    equals = top_class == labels.view(*top_class.shape)\n                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\"\"\"\n\n                   \n            print(f\"Epoch {epoch+1}/{epochs}.. \"\n                  f\"Train loss: {running_loss/print_every:.3f}..\"\n                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n                  f\"Test Accuracy: {accuracy/len(testloader):.3f}..\")\n            running_loss = 0\n            model.train()\n    torch.save(model.state_dict(), 'checkpoint.pth')",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1970ab46b5e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Move input and label tensors to the default device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {
        "tags": [],
        "cell_id": "00009-015ffb55-b626-4162-be33-526b907c8033",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00010-1419567c-94f7-4ea9-920a-8564a628e15c",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "27d9e668",
        "execution_millis": 6,
        "execution_start": 1616507973758,
        "deepnote_cell_type": "code"
      },
      "source": "len(data)",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "434"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {
        "tags": [],
        "cell_id": "00009-4177f1ad-38f1-48bf-ad2e-5721eb5dff43",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_variable_name": "input_1",
        "deepnote_variable_value": "",
        "cell_id": "00009-13434bbf-c95f-49d0-8a0f-902f002c02f1",
        "deepnote_to_be_reexecuted": true,
        "source_hash": "b623e53d",
        "execution_millis": 1,
        "deepnote_cell_type": "input-text"
      },
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {
        "tags": [],
        "cell_id": "00008-bc14380c-0d51-4289-b848-d065634e38bf",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=9f1e7bdb-154a-4549-a646-7775bf1dc7a2' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote_notebook_id": "344baa96-9ad7-4662-9343-c2d6a5fa5f2c",
    "deepnote": {},
    "deepnote_execution_queue": []
  }
}